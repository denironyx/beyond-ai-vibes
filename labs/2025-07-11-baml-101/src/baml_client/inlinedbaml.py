# ----------------------------------------------------------------------------
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
# ----------------------------------------------------------------------------

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code using: baml-cli generate
# baml-cli is available with the baml package.

_file_map = {

    "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\nclient<llm> CustomGPT4o {\n  provider openai\n  options {\n    model \"gpt-4o\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT4oMini {\n  provider openai\n  retry_policy Exponential\n  options {\n    model \"gpt-4o-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomSonnet {\n  provider anthropic\n  options {\n    model \"claude-3-5-sonnet-20241022\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n\nclient<llm> CustomHaiku {\n  provider anthropic\n  retry_policy Constant\n  options {\n    model \"claude-3-haiku-20240307\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/round-robin\nclient<llm> CustomFast {\n  provider round-robin\n  options {\n    // This will alternate between the two clients\n    strategy [CustomGPT4oMini, CustomHaiku]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/fallback\nclient<llm> OpenaiFallback {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [CustomGPT4oMini, CustomGPT4oMini]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Constant {\n  max_retries 3\n  // Strategy is optional\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  // Strategy is optional\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    multiplier 1.5\n    max_delay_ms 10000\n  }\n}",
    "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.201.0\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode sync\n}\n",
    "get_order_info.baml": "class Email {\n    subject string @description(\"The subject of the email\")\n    body string @description(\"The body content of the email\")\n    from_address string @description(\"The sender's email address\")\n}\n\ntemplate_string ChainOfThought(action: string?) #\"\n    Before you answer, please explain your reasoning step-by-step.\n    {% if action %}{{ action }}{% endif %}\n    \n    For example:\n    If we think step by step we can see that ...\n    Therefore the output is:\n    {\n      ... // schema\n    }\n\"#\n\n\nfunction GetOrderInfo(email: Email) -> OrderInfo {\n  client \"openai/gpt-\"\n  prompt #\"\n    extract everything from this email.\n\n\n    {{ ctx.output_format }}\n\n    Outline some relevant information before you answer.\n    Example:\n    - ...\n    - ...\n    ...\n    {\n      ... // schema\n    }\n\n    {{ _.role('user') }}\n\n    Sender: {{email.from_address}}\n    Email Subject: {{email.subject}}\n    Email Body: {{email.body}}\n  \"#\n}\n\n\n// function GetOrderInfo(email: Email) -> OrderInfo {\n//   // Specify a client as provider/model-name\n//   // you can use custom LLM params with a custom client name from clients.baml like \"client CustomHaiku\"\n//   client \"openai/gpt-4o\" // Set OPENAI_API_KEY to use this client.\n//   prompt #\"\n//     Extract everything from this email.\n\n//     {{ ctx.output_format }}\n\n//     {{ ChainOfThought(\"focus on things related to shipping\") }}\n\n//     Before you answer, please explain your reasoning step by step.\n\n//     For example:\n//     If we think step by step we can see that ... \n\n//     Therefore the output is:\n//     {\n//     ... // schema\n//     }\n    \n//     {{ _.role(\"user\") }}\n\n//     Sender: {{ email.from_address }}\n//     Email Subject: {{ email.subject }}\n//     Email Body: {{ email.body }}\n//   \"#\n// }\n\n\n\n\nclass OrderInfo {\n    order_status \"ORDERED\" | \"SHIPPED\" | \"DELIVERED\" | \"CANCELLED\"\n    tracking_number string?\n    estimated_delivery_date string?\n}\n\ntest Test1 {\n    functions [GetOrderInfo]\n    args {\n        email {\n            from_address \"hello@amazon.com\"\n            subject \"Your Amazon Order Confirmation of 'Wood Dowel Rods...' has shipped!\"\n            body #\"\n                Hi Sam, your package will arrive:\n                Thurs, April 4\n                Track your package:\n                www.amazon.com/gp/your-account/ship-track?ie=23&orderId123\n                On the way:\n                Wood Dowel Rods...\n                Order #113-7540940\n                Ship to:\n                    Sam\n                    SEATTLE, WA\n                Shipment total:\n                $0.00\n            \"#\n\n        }\n    }\n}",
    "resume.baml": "// Defining a data model.\nclass Resume {\n  name string\n  email string\n  experience string[]\n  skills string[]\n}\n\n// Create a function to extract the resume from a string.\nfunction ExtractResume(resume: string) -> Resume {\n  // Specify a client as provider/model-name\n  // you can use custom LLM params with a custom client name from clients.baml like \"client CustomHaiku\"\n  client \"openai/gpt-4o\" // Set OPENAI_API_KEY to use this client.\n  prompt #\"\n    Extract from this content:\n    {{ resume }}\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n\n\n// Test the function with a sample resume. Open the VSCode playground to run this.\ntest vaibhav_resume {\n  functions [ExtractResume]\n  args {\n    resume #\"\n      Vaibhav Gupta\n      vbv@boundaryml.com\n\n      Experience:\n      - Founder at BoundaryML\n      - CV Engineer at Google\n      - CV Engineer at Microsoft\n\n      Skills:\n      - Rust\n      - C++\n    \"#\n  }\n}\n",
    "spam_classifier.baml": "enum SpamType {\n    Spam\n    NotSpam\n}\n\n// ClassifyText function to classify input text as Spam or NotSpam\nfunction ClassifyText(input: string) -> SpamType {\n    client \"openai/gpt-4o-mini\"\n    prompt #\"\n        Please classify the following text as either 'Spam' or 'NotSpam': \n        \n        {{ ctx.output_format }}\n\n        {{ _.role(\"system\") }}\n        \n        {{ _.role(\"user\") }}\n\n        {{ input }}\n    \"#\n}\n\n// Test the classifier\n\n\ntest BasicSpamTest {\n    functions [ClassifyText]\n    args {\n        input \"Congratulations! You've won a free iPhone! Click here to claim your prize.\"\n    }\n}\n\ntest BasicNotSpamTest {\n    functions [ClassifyText]\n    args {\n        input \"Hello Dennis, I hope you are having a great day! I wanted to check in on the project status and see if you need any assistance.\"\n    }\n}\n",
    "ticket_classifier.baml": "// Multi-Lable Classification\n\n// Define the labels Enum and Schema\nenum TicketLabel {\n    ACCOUNT\n    BILLING\n    GENERAL_QUERY\n}\n\nclass TicketClassification {\n    labels TicketLabel[]\n}\n\n\n// Create the Multi-Label Classification function\n\nfunction ClassifyTicket(ticket: string) -> TicketLabel[] {\n    // Specify a client as provider/model-name\n    // you can use custom LLM params with a custom client name from clients.baml like \"client CustomHaiku\"\n    client \"openai/gpt-4o-mini\" // Set OPENAI_API_KEY to use this client.\n    prompt #\"\n        You are a support agent at a tech company. Analyze the support ticket and select all applicable labels from the following list:\n                 \n        {{ ctx.output_format }}\n\n        {{ _.role(\"user\") }}\n\n        {{ ticket }}\n    \"# \n}\n\n\n// Test the Multi-Label Classification function\n\ntest ClassifyTicketSingleLabel {\n    functions [ClassifyTicket]\n    args {\n        ticket \"I have a question about my account settings.\"\n    }\n}\n\ntest ClassifyTicketMultipleLabels {\n    functions [ClassifyTicket]\n    args {\n        ticket \"My Account is locked and I need help with billing issues.\"\n    }\n}",
}

def get_baml_files():
    return _file_map